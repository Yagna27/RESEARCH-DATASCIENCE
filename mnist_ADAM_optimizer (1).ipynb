{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-- ADAM optimizer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hea1431mAnT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vnmdCelm82t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f827399b-dd22-4508-9df0-a4ab3fe899cb"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbrxc_rxnXyL",
        "outputId": "553bb33b-ff52-45fa-ad43-a1a8e46ac8ee"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX9ZdOVxn0cc",
        "outputId": "70aae21f-a8f3-44df-b2f7-e6fbd3e7b95c"
      },
      "source": [
        "len(x_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDi-Y71CpqZf",
        "outputId": "6f0643ed-f692-4956-88f4-518991eee47e"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjZFJQIbxV-m",
        "outputId": "37ecdaff-941c-4022-b520-b29a5ca5094b"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUdlPP_JnXKR"
      },
      "source": [
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "IvoyOvVI0vMe",
        "outputId": "6e0282b1-46da-45fa-f1cc-55c80b9b4c33"
      },
      "source": [
        "plt.matshow(x_train[11])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe4dbce0490>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ_MMej41yk3",
        "outputId": "98da6c2a-0f1b-4050-dd28-042074b4f721"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXVizb6h2OUZ",
        "outputId": "e54d72a9-0482-4728-969a-18bddfe28c2e"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ixsg3e2anm"
      },
      "source": [
        "x_train_flattened=x_train.reshape(len(x_train),28*28)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ATXwtME2kbs",
        "outputId": "d037e6e6-7ed3-4f3c-f2d2-4ef23f0f0da2"
      },
      "source": [
        "x_train_flattened.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1GYWviC26m1"
      },
      "source": [
        "x_test_flattened=x_test.reshape(len(x_test),28*28)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI0YQm0z3Fjr",
        "outputId": "ac8994fc-0fb7-4439-a588-66515054490d"
      },
      "source": [
        "x_test_flattened.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5GNmz6v3I9P",
        "outputId": "f095592f-0927-43b1-b330-f855cb543fb5"
      },
      "source": [
        "x_train_flattened[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
              "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
              "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
              "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
              "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
              "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
              "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
              "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
              "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
              "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
              "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
              "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
              "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIdv-YEy_Bbk"
      },
      "source": [
        "dense single layer with ADAM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idFw_VCB3eRY"
      },
      "source": [
        "modelA1=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')     \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYjJXiw44Ye8"
      },
      "source": [
        "modelA1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ge7CD905loy",
        "outputId": "65b66323-2eb2-499f-9635-4119ec24786b"
      },
      "source": [
        "modelA1.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 9.3326 - accuracy: 0.8423\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 6.0202 - accuracy: 0.8783\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 5.7024 - accuracy: 0.8816\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 5.5525 - accuracy: 0.8860\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 5.3124 - accuracy: 0.8873\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a07f222d0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sjDNxzLLSBv"
      },
      "source": [
        "dense two-layer with ADAM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oORp-_Gp6AyD"
      },
      "source": [
        "modelA2=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWbz9hFPGdWB"
      },
      "source": [
        "modelA2.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F6nBCIHGmiG",
        "outputId": "9b0f3cac-e798-4419-cf42-f09530a0e15d"
      },
      "source": [
        "modelA2.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2600 - accuracy: 0.6565\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6775 - accuracy: 0.8114\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5983 - accuracy: 0.8248\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5383 - accuracy: 0.8427\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5329 - accuracy: 0.8441\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a08675b50>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33Q7kegjLtap"
      },
      "source": [
        "dense 3-layer with ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcWfkEZ9Gq-E",
        "outputId": "aacce668-d0b8-48af-a1f0-3f8c806a5c94"
      },
      "source": [
        "modelA3=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA3.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA3.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.6979 - accuracy: 0.4878\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1066 - accuracy: 0.6492\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8888 - accuracy: 0.7049\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7778 - accuracy: 0.7474\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7223 - accuracy: 0.7746\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a0840b9d0>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTzMEBfMMFdo"
      },
      "source": [
        "dense 4-layer with ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zWZyFetL4ly",
        "outputId": "5dd9275d-1121-476e-e5a7-d73cc194b3b8"
      },
      "source": [
        "modelA4=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA4.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA4.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7748 - accuracy: 0.4165\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1262 - accuracy: 0.6355\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9117 - accuracy: 0.7199\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7457 - accuracy: 0.7880\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6692 - accuracy: 0.8061\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a081e41d0>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUC51IIPNFsQ"
      },
      "source": [
        "dense 5-layer with ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxemNX9RMXUB",
        "outputId": "d320d5e6-7474-4281-8884-293a1c40f1f2"
      },
      "source": [
        "modelA5=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')\n",
        "                \n",
        "])\n",
        "modelA5.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA5.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.0406 - accuracy: 0.2428\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.5085 - accuracy: 0.4504\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2869 - accuracy: 0.5163\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1559 - accuracy: 0.5599\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0630 - accuracy: 0.6327\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a07f6d5d0>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiM7pJ3NNT3b"
      },
      "source": [
        "ADAM1ACC=[0.8873,0.8441,0.7746,0.8061,0.6327] #accuracy of above five models keeping epochs and parameters constant "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRd857AmOETI",
        "outputId": "ef484015-2adf-4846-bc72-452a44c0555f"
      },
      "source": [
        "modelA11=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')\n",
        "                \n",
        "])\n",
        "modelA11.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA11.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.7179 - accuracy: 0.3382\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.3970 - accuracy: 0.5013\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.1651 - accuracy: 0.6394\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 1.0400 - accuracy: 0.6743\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9572 - accuracy: 0.7146\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a07d42a90>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VvQgGgrOTIm",
        "outputId": "154a5ca9-6bd0-43bd-e669-b0482d6722be"
      },
      "source": [
        "modelA12=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA12.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA12.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.7550 - accuracy: 0.4165\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8760 - accuracy: 0.7084\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6854 - accuracy: 0.7840\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5985 - accuracy: 0.8206\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5749 - accuracy: 0.8298\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a02ed4690>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuSo4NrWO_4z",
        "outputId": "0b994741-1254-4a29-e0fc-8442a8129e17"
      },
      "source": [
        "modelA13=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA13.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA13.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 4ms/step - loss: 0.8982 - accuracy: 0.7035\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3966 - accuracy: 0.8887\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3079 - accuracy: 0.9080\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2662 - accuracy: 0.9194\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2425 - accuracy: 0.9271\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe4d010bd10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0V2qjs-Pau2"
      },
      "source": [
        "ADAM2ACC=[0.8873,0.7146, 0.8298,0.8177] #accuracy of above four models keeping epochs  constant  and increases parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LcywFKk84_R",
        "outputId": "f5f74428-dd63-46ea-8345-99acbfb679ba"
      },
      "source": [
        "modelA132=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA132.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA132.fit(x_train_flattened,y_train,epochs=20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8399 - accuracy: 0.7311\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3726 - accuracy: 0.8925\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2987 - accuracy: 0.9115\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2641 - accuracy: 0.9212\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2390 - accuracy: 0.9289\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2211 - accuracy: 0.9337\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2066 - accuracy: 0.9377\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1957 - accuracy: 0.9416\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1873 - accuracy: 0.9440\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1798 - accuracy: 0.9452\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1733 - accuracy: 0.9473\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1679 - accuracy: 0.9494\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1626 - accuracy: 0.9505\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1579 - accuracy: 0.9516\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1546 - accuracy: 0.9521\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1502 - accuracy: 0.9531\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1472 - accuracy: 0.9546\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1446 - accuracy: 0.9553\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1407 - accuracy: 0.9563\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1382 - accuracy: 0.9571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe4d0055750>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-aEeanZQRj3",
        "outputId": "10326d90-95bd-48c1-b17d-7dafdd185fa4"
      },
      "source": [
        "modelA133=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA133.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA133.fit(x_train_flattened,y_train,epochs=70)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8928 - accuracy: 0.6969\n",
            "Epoch 2/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3901 - accuracy: 0.8873\n",
            "Epoch 3/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3095 - accuracy: 0.9119\n",
            "Epoch 4/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2753 - accuracy: 0.9202\n",
            "Epoch 5/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2530 - accuracy: 0.9262\n",
            "Epoch 6/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2373 - accuracy: 0.9301\n",
            "Epoch 7/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2232 - accuracy: 0.9350\n",
            "Epoch 8/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2127 - accuracy: 0.9373\n",
            "Epoch 9/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2012 - accuracy: 0.9402\n",
            "Epoch 10/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1945 - accuracy: 0.9418\n",
            "Epoch 11/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1873 - accuracy: 0.9429\n",
            "Epoch 12/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1823 - accuracy: 0.9445\n",
            "Epoch 13/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1764 - accuracy: 0.9466\n",
            "Epoch 14/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1712 - accuracy: 0.9480\n",
            "Epoch 15/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1670 - accuracy: 0.9492\n",
            "Epoch 16/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1637 - accuracy: 0.9494\n",
            "Epoch 17/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1605 - accuracy: 0.9501\n",
            "Epoch 18/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1570 - accuracy: 0.9512\n",
            "Epoch 19/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1533 - accuracy: 0.9517\n",
            "Epoch 20/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1508 - accuracy: 0.9536\n",
            "Epoch 21/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1483 - accuracy: 0.9536\n",
            "Epoch 22/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1454 - accuracy: 0.9548\n",
            "Epoch 23/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1423 - accuracy: 0.9551\n",
            "Epoch 24/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1393 - accuracy: 0.9557\n",
            "Epoch 25/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1384 - accuracy: 0.9560\n",
            "Epoch 26/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1349 - accuracy: 0.9573\n",
            "Epoch 27/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1334 - accuracy: 0.9586\n",
            "Epoch 28/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1317 - accuracy: 0.9581\n",
            "Epoch 29/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1293 - accuracy: 0.9595\n",
            "Epoch 30/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1281 - accuracy: 0.9593\n",
            "Epoch 31/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1254 - accuracy: 0.9598\n",
            "Epoch 32/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1232 - accuracy: 0.9608\n",
            "Epoch 33/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1214 - accuracy: 0.9611\n",
            "Epoch 34/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1193 - accuracy: 0.9625\n",
            "Epoch 35/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1181 - accuracy: 0.9624\n",
            "Epoch 36/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1171 - accuracy: 0.9630\n",
            "Epoch 37/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1151 - accuracy: 0.9637\n",
            "Epoch 38/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1135 - accuracy: 0.9643\n",
            "Epoch 39/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1125 - accuracy: 0.9641\n",
            "Epoch 40/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1111 - accuracy: 0.9647\n",
            "Epoch 41/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1098 - accuracy: 0.9649\n",
            "Epoch 42/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1088 - accuracy: 0.9653\n",
            "Epoch 43/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1069 - accuracy: 0.9660\n",
            "Epoch 44/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1064 - accuracy: 0.9666\n",
            "Epoch 45/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1045 - accuracy: 0.9665\n",
            "Epoch 46/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1044 - accuracy: 0.9663\n",
            "Epoch 47/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1033 - accuracy: 0.9674\n",
            "Epoch 48/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1020 - accuracy: 0.9676\n",
            "Epoch 49/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1009 - accuracy: 0.9674\n",
            "Epoch 50/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1006 - accuracy: 0.9680\n",
            "Epoch 51/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0988 - accuracy: 0.9682\n",
            "Epoch 52/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0985 - accuracy: 0.9681\n",
            "Epoch 53/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0969 - accuracy: 0.9686\n",
            "Epoch 54/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0954 - accuracy: 0.9693\n",
            "Epoch 55/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0941 - accuracy: 0.9696\n",
            "Epoch 56/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0934 - accuracy: 0.9695\n",
            "Epoch 57/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0930 - accuracy: 0.9695\n",
            "Epoch 58/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0917 - accuracy: 0.9707\n",
            "Epoch 59/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0919 - accuracy: 0.9703\n",
            "Epoch 60/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0908 - accuracy: 0.9708\n",
            "Epoch 61/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0897 - accuracy: 0.9711\n",
            "Epoch 62/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0896 - accuracy: 0.9714\n",
            "Epoch 63/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0886 - accuracy: 0.9711\n",
            "Epoch 64/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0878 - accuracy: 0.9712\n",
            "Epoch 65/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0870 - accuracy: 0.9711\n",
            "Epoch 66/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0851 - accuracy: 0.9719\n",
            "Epoch 67/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0848 - accuracy: 0.9724\n",
            "Epoch 68/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0836 - accuracy: 0.9728\n",
            "Epoch 69/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0836 - accuracy: 0.9724\n",
            "Epoch 70/70\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0828 - accuracy: 0.9734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe463d8c210>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3zDnTERQyGu",
        "outputId": "cc1a601a-50c8-4236-96f7-06596863abb1"
      },
      "source": [
        "modelA131=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA131.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA131.fit(x_train_flattened,y_train,epochs=50)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.8328 - accuracy: 0.7247\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3788 - accuracy: 0.8918\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3277 - accuracy: 0.9053\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2966 - accuracy: 0.9124\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2687 - accuracy: 0.9196\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2455 - accuracy: 0.9270\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2282 - accuracy: 0.9312\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2144 - accuracy: 0.9355\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2032 - accuracy: 0.9395\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1928 - accuracy: 0.9415\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1855 - accuracy: 0.9443\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1797 - accuracy: 0.9457\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1739 - accuracy: 0.9465\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1689 - accuracy: 0.9483\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1642 - accuracy: 0.9496\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1611 - accuracy: 0.9508\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1570 - accuracy: 0.9509\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1528 - accuracy: 0.9526\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1505 - accuracy: 0.9527\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1472 - accuracy: 0.9531\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1449 - accuracy: 0.9542\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1426 - accuracy: 0.9553\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1394 - accuracy: 0.9556\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1389 - accuracy: 0.9562\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1359 - accuracy: 0.9569\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1335 - accuracy: 0.9575\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1319 - accuracy: 0.9575\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1283 - accuracy: 0.9593\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1277 - accuracy: 0.9596\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1250 - accuracy: 0.9605\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1234 - accuracy: 0.9607\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1213 - accuracy: 0.9605\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1206 - accuracy: 0.9611\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1188 - accuracy: 0.9617\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1171 - accuracy: 0.9621\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1148 - accuracy: 0.9629\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1129 - accuracy: 0.9633\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1111 - accuracy: 0.9641\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1110 - accuracy: 0.9647\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1089 - accuracy: 0.9646\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1071 - accuracy: 0.9648\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1054 - accuracy: 0.9657\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1037 - accuracy: 0.9663\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1037 - accuracy: 0.9664\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1024 - accuracy: 0.9665\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1013 - accuracy: 0.9664\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1000 - accuracy: 0.9673\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0984 - accuracy: 0.9676\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0971 - accuracy: 0.9677\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0960 - accuracy: 0.9686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe463e64190>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZVZ7gBLQ1wS",
        "outputId": "5e2101b7-4327-4437-dc68-cc43be598b35"
      },
      "source": [
        "modelA134=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "modelA134.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelA134.fit(x_train_flattened,y_train,epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8995 - accuracy: 0.7081\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3951 - accuracy: 0.8894\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3132 - accuracy: 0.9102\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2769 - accuracy: 0.9197\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2537 - accuracy: 0.9260\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2366 - accuracy: 0.9302\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2223 - accuracy: 0.9345\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2106 - accuracy: 0.9380\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2011 - accuracy: 0.9396\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1925 - accuracy: 0.9417\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1859 - accuracy: 0.9439\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1812 - accuracy: 0.9455\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1743 - accuracy: 0.9471\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1706 - accuracy: 0.9471\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1658 - accuracy: 0.9488\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1618 - accuracy: 0.9497\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1576 - accuracy: 0.9509\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1557 - accuracy: 0.9520\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1506 - accuracy: 0.9531\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1484 - accuracy: 0.9534\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1450 - accuracy: 0.9542\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1420 - accuracy: 0.9560\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1391 - accuracy: 0.9565\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1372 - accuracy: 0.9563\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1344 - accuracy: 0.9578\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1321 - accuracy: 0.9579\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1298 - accuracy: 0.9588\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1279 - accuracy: 0.9594\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1264 - accuracy: 0.9600\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1236 - accuracy: 0.9604\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1212 - accuracy: 0.9611\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1199 - accuracy: 0.9614\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1181 - accuracy: 0.9621\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1158 - accuracy: 0.9628\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1146 - accuracy: 0.9633\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1118 - accuracy: 0.9639\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1113 - accuracy: 0.9640\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1092 - accuracy: 0.9643\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1071 - accuracy: 0.9650\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1051 - accuracy: 0.9654\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1052 - accuracy: 0.9654\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1027 - accuracy: 0.9656\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1020 - accuracy: 0.9668\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0995 - accuracy: 0.9678\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0977 - accuracy: 0.9686\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0971 - accuracy: 0.9685\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0953 - accuracy: 0.9687\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0932 - accuracy: 0.9693\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0939 - accuracy: 0.9697\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0920 - accuracy: 0.9699\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0904 - accuracy: 0.9703\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0894 - accuracy: 0.9701\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0868 - accuracy: 0.9718\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0867 - accuracy: 0.9711\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0871 - accuracy: 0.9707\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0848 - accuracy: 0.9711\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0835 - accuracy: 0.9724\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0821 - accuracy: 0.9724\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0814 - accuracy: 0.9724\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0804 - accuracy: 0.9732\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0784 - accuracy: 0.9736\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0774 - accuracy: 0.9740\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0771 - accuracy: 0.9736\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0765 - accuracy: 0.9739\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0740 - accuracy: 0.9744\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0741 - accuracy: 0.9748\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0728 - accuracy: 0.9750\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0718 - accuracy: 0.9756\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0710 - accuracy: 0.9751\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0688 - accuracy: 0.9761\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0692 - accuracy: 0.9757\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0683 - accuracy: 0.9765\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0672 - accuracy: 0.9769\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0657 - accuracy: 0.9773\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0651 - accuracy: 0.9775\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0643 - accuracy: 0.9776\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0632 - accuracy: 0.9780\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0627 - accuracy: 0.9784\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0620 - accuracy: 0.9782\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0603 - accuracy: 0.9792\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0591 - accuracy: 0.9794\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0579 - accuracy: 0.9800\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0601 - accuracy: 0.9793\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0573 - accuracy: 0.9798\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0568 - accuracy: 0.9805\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0563 - accuracy: 0.9804\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0548 - accuracy: 0.9814\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0540 - accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0530 - accuracy: 0.9815\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0537 - accuracy: 0.9809\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0525 - accuracy: 0.9812\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0511 - accuracy: 0.9822\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0505 - accuracy: 0.9822\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0490 - accuracy: 0.9832\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0491 - accuracy: 0.9825\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0489 - accuracy: 0.9825\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0492 - accuracy: 0.9823\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0470 - accuracy: 0.9833\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0471 - accuracy: 0.9832\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0446 - accuracy: 0.9844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe463c42950>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezI3r2Y6RIIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wii2nFm3RSJs"
      },
      "source": [
        " "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C9qlz4YnPSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82133998-3fcf-4456-8c11-40a91ed17c64"
      },
      "source": [
        "y_pred_adam1=modelA13.predict(x_test_flattened)\n",
        "y_pred_adamf1=[np.argmax(i) for i in y_pred_adam1]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adam_acc1=accuracy_score(y_pred_adamf1,y_test)\n",
        "print(adam_acc1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by5NesVBmHrF",
        "outputId": "bbb9e2e0-34ec-48d2-a635-94e6a5ac62eb"
      },
      "source": [
        "y_pred_adam2=modelA132.predict(x_test_flattened)\n",
        "y_pred_adamf2=[np.argmax(i) for i in y_pred_adam2]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adam_acc2=accuracy_score(y_pred_adamf2,y_test)\n",
        "print(adam_acc2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHzXlnBneXXK",
        "outputId": "a8be4873-c4ff-4942-aa0d-6aedb9014802"
      },
      "source": [
        "y_pred_adam3=modelA131.predict(x_test_flattened)\n",
        "y_pred_adamf3=[np.argmax(i) for i in y_pred_adam3]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adam_acc3=accuracy_score(y_pred_adamf3,y_test)\n",
        "print(adam_acc3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWa-UiokehEV",
        "outputId": "86eb9111-fd81-4955-f4be-9ebb0b8fd70d"
      },
      "source": [
        "y_pred_adam4=modelA133.predict(x_test_flattened)\n",
        "y_pred_adamf4=[np.argmax(i) for i in y_pred_adam4]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adam_acc4=accuracy_score(y_pred_adamf4,y_test)\n",
        "print(adam_acc4)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq86dYyjeoUz",
        "outputId": "4a758fd7-cbcd-47e5-f51e-112fb13ffeac"
      },
      "source": [
        "y_pred_adam5=modelA134.predict(x_test_flattened)\n",
        "y_pred_adamf5=[np.argmax(i) for i in y_pred_adam5]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adam_acc5=accuracy_score(y_pred_adamf5,y_test)\n",
        "print(adam_acc5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U152JYfoJU5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAy7uQlCqHc_"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7HjuHtnqsPW"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulkxcgg1q-YK"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NATsc-nkraLv"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTp3myT4vc9b"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvXYMybNveoV"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-taL4DvxzY2"
      },
      "source": [
        "SGd --Gradient descent (with momentum) optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8CRVKriwT2U",
        "outputId": "b0638baa-a07d-49cd-876c-44cb8ee7abf3"
      },
      "source": [
        "modelSGD=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(16,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(128,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(256,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "modelSGD.compile(\n",
        "    optimizer=opt,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "modelSGD.fit(x_train_flattened,y_train,epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.2242 - accuracy: 0.1616\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1511 - accuracy: 0.5801\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7272 - accuracy: 0.7789\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5606 - accuracy: 0.8455\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4573 - accuracy: 0.8747\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3976 - accuracy: 0.8907\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3581 - accuracy: 0.8997\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3275 - accuracy: 0.9083\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.9138\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2851 - accuracy: 0.9186\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62b0b51b50>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwacIcFsyMtM"
      },
      "source": [
        "y_pred_sgd=modelSGD.predict(x_test_flattened)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Kq2Hijy05q"
      },
      "source": [
        "y_pred_SGDf=[np.argmax(i) for i in y_pred_sgd]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svBt1PHvy6_B",
        "outputId": "b07caeb2-e82a-49a0-f427-76faa6ae0edb"
      },
      "source": [
        "ACC_sgd=accuracy_score(y_pred_SGDf,y_test)\n",
        "print(ACC_sgd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYxoXI2UzFlH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}