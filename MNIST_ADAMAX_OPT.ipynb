{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST--ADAMAX--OPT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "suF8Tij6klto"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwsdniAvkwsF",
        "outputId": "bab26666-8b58-404d-8fed-92e3502eb754"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMYm1EtfkzN2"
      },
      "source": [
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16GcaziGk2Tl"
      },
      "source": [
        "x_train_flattened=x_train.reshape(len(x_train),28*28)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To0roRKck5Do"
      },
      "source": [
        "x_test_flattened=x_test.reshape(len(x_test),28*28)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E90m1PMnk7KY",
        "outputId": "f1cdf246-b0bb-457c-f63e-57a77b87abad"
      },
      "source": [
        "pip install tensorflow-addons"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoqRkEMUk-Hf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLl8lz-PlCLf",
        "outputId": "92b168b1-0d70-49b2-b08e-d2ef7d31ec6c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "model_adamax1=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "model_adamax1.compile(\n",
        "    optimizer='Adamax',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model_adamax1.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 1.2828 - accuracy: 0.5774\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5695 - accuracy: 0.8395\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.4698 - accuracy: 0.8713\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.4178 - accuracy: 0.8823\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3792 - accuracy: 0.8934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a4657e290>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5yGo4kSlfRo",
        "outputId": "451d2e2d-2def-4ace-d9c1-4b323f05daad"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "model_adamax2=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "model_adamax2.compile(\n",
        "    optimizer='Adamax',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model_adamax2.fit(x_train_flattened,y_train,epochs=20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 1.3230 - accuracy: 0.5559\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5955 - accuracy: 0.8292\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4895 - accuracy: 0.8638\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.4275 - accuracy: 0.8802\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3851 - accuracy: 0.8905\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3546 - accuracy: 0.8983\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3301 - accuracy: 0.9043\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.3115 - accuracy: 0.9105\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2952 - accuracy: 0.9147\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2801 - accuracy: 0.9194\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2680 - accuracy: 0.9230\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2581 - accuracy: 0.9247\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2483 - accuracy: 0.9279\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2396 - accuracy: 0.9299\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2317 - accuracy: 0.9337\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2252 - accuracy: 0.9351\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2184 - accuracy: 0.9368\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2125 - accuracy: 0.9384\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2085 - accuracy: 0.9389\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2039 - accuracy: 0.9404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a464d3110>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkDwWx6-nEW0",
        "outputId": "544a0cfd-71d1-4c59-e7de-0d81450b2234"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "model_adamax3=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "model_adamax3.compile(\n",
        "    optimizer='Adamax',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model_adamax3.fit(x_train_flattened,y_train,epochs=50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 1.3883 - accuracy: 0.5203\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5984 - accuracy: 0.8235\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4589 - accuracy: 0.8694\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3973 - accuracy: 0.8869\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3640 - accuracy: 0.8954\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3402 - accuracy: 0.9021\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3200 - accuracy: 0.9072\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3038 - accuracy: 0.9127\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2894 - accuracy: 0.9148\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2772 - accuracy: 0.9184\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2675 - accuracy: 0.9212\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2588 - accuracy: 0.9226\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2512 - accuracy: 0.9254\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2462 - accuracy: 0.9266\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2404 - accuracy: 0.9286\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2356 - accuracy: 0.9302\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2319 - accuracy: 0.9304\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2278 - accuracy: 0.9315\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2236 - accuracy: 0.9331\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2198 - accuracy: 0.9339\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2172 - accuracy: 0.9353\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2143 - accuracy: 0.9358\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2109 - accuracy: 0.9369\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2083 - accuracy: 0.9382\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2058 - accuracy: 0.9384\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2031 - accuracy: 0.9390\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2011 - accuracy: 0.9398\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1984 - accuracy: 0.9408\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1962 - accuracy: 0.9409\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1946 - accuracy: 0.9426\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1918 - accuracy: 0.9424\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1907 - accuracy: 0.9426\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1885 - accuracy: 0.9437\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1869 - accuracy: 0.9442\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1846 - accuracy: 0.9446\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1831 - accuracy: 0.9452\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1812 - accuracy: 0.9455\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1798 - accuracy: 0.9462\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1776 - accuracy: 0.9471\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1762 - accuracy: 0.9481\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1748 - accuracy: 0.9474\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1737 - accuracy: 0.9484\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1724 - accuracy: 0.9485\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1716 - accuracy: 0.9487\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1691 - accuracy: 0.9493\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1687 - accuracy: 0.9495\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1668 - accuracy: 0.9502\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1664 - accuracy: 0.9509\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1652 - accuracy: 0.9513\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1641 - accuracy: 0.9515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a4638b950>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikXvMyB8n5xb",
        "outputId": "2bbe62f2-d4a3-4243-ede1-388e6f99fd6f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "model_adamax4=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "model_adamax4.compile(\n",
        "    optimizer='Adamax',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model_adamax4.fit(x_train_flattened,y_train,epochs=70)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 1.3928 - accuracy: 0.5227\n",
            "Epoch 2/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6156 - accuracy: 0.8126\n",
            "Epoch 3/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4621 - accuracy: 0.8638\n",
            "Epoch 4/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3898 - accuracy: 0.8842\n",
            "Epoch 5/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3481 - accuracy: 0.8960\n",
            "Epoch 6/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3205 - accuracy: 0.9049\n",
            "Epoch 7/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2993 - accuracy: 0.9115\n",
            "Epoch 8/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2821 - accuracy: 0.9169\n",
            "Epoch 9/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2684 - accuracy: 0.9215\n",
            "Epoch 10/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2597 - accuracy: 0.9235\n",
            "Epoch 11/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2511 - accuracy: 0.9258\n",
            "Epoch 12/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2437 - accuracy: 0.9285\n",
            "Epoch 13/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2375 - accuracy: 0.9301\n",
            "Epoch 14/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2331 - accuracy: 0.9319\n",
            "Epoch 15/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2271 - accuracy: 0.9328\n",
            "Epoch 16/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2228 - accuracy: 0.9342\n",
            "Epoch 17/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2196 - accuracy: 0.9353\n",
            "Epoch 18/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2154 - accuracy: 0.9366\n",
            "Epoch 19/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2119 - accuracy: 0.9363\n",
            "Epoch 20/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2075 - accuracy: 0.9383\n",
            "Epoch 21/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2046 - accuracy: 0.9398\n",
            "Epoch 22/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2014 - accuracy: 0.9406\n",
            "Epoch 23/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1989 - accuracy: 0.9413\n",
            "Epoch 24/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1955 - accuracy: 0.9429\n",
            "Epoch 25/70\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1926 - accuracy: 0.9427\n",
            "Epoch 26/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1897 - accuracy: 0.9438\n",
            "Epoch 27/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1882 - accuracy: 0.9449\n",
            "Epoch 28/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1849 - accuracy: 0.9449\n",
            "Epoch 29/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1836 - accuracy: 0.9453\n",
            "Epoch 30/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1805 - accuracy: 0.9466\n",
            "Epoch 31/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1788 - accuracy: 0.9471\n",
            "Epoch 32/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1769 - accuracy: 0.9469\n",
            "Epoch 33/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1750 - accuracy: 0.9481\n",
            "Epoch 34/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1741 - accuracy: 0.9481\n",
            "Epoch 35/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1720 - accuracy: 0.9485\n",
            "Epoch 36/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1703 - accuracy: 0.9498\n",
            "Epoch 37/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1695 - accuracy: 0.9494\n",
            "Epoch 38/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1675 - accuracy: 0.9495\n",
            "Epoch 39/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1663 - accuracy: 0.9507\n",
            "Epoch 40/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1652 - accuracy: 0.9506\n",
            "Epoch 41/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1637 - accuracy: 0.9510\n",
            "Epoch 42/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1628 - accuracy: 0.9508\n",
            "Epoch 43/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1613 - accuracy: 0.9517\n",
            "Epoch 44/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1601 - accuracy: 0.9516\n",
            "Epoch 45/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1591 - accuracy: 0.9524\n",
            "Epoch 46/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1577 - accuracy: 0.9527\n",
            "Epoch 47/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1570 - accuracy: 0.9527\n",
            "Epoch 48/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1551 - accuracy: 0.9532\n",
            "Epoch 49/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1548 - accuracy: 0.9537\n",
            "Epoch 50/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1540 - accuracy: 0.9539\n",
            "Epoch 51/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1530 - accuracy: 0.9535\n",
            "Epoch 52/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1520 - accuracy: 0.9542\n",
            "Epoch 53/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1510 - accuracy: 0.9545\n",
            "Epoch 54/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1507 - accuracy: 0.9542\n",
            "Epoch 55/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1492 - accuracy: 0.9557\n",
            "Epoch 56/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1487 - accuracy: 0.9554\n",
            "Epoch 57/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1477 - accuracy: 0.9559\n",
            "Epoch 58/70\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1473 - accuracy: 0.9556\n",
            "Epoch 59/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1473 - accuracy: 0.9557\n",
            "Epoch 60/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1452 - accuracy: 0.9567\n",
            "Epoch 61/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1451 - accuracy: 0.9562\n",
            "Epoch 62/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1441 - accuracy: 0.9564\n",
            "Epoch 63/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1437 - accuracy: 0.9570\n",
            "Epoch 64/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1427 - accuracy: 0.9570\n",
            "Epoch 65/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1422 - accuracy: 0.9571\n",
            "Epoch 66/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1416 - accuracy: 0.9573\n",
            "Epoch 67/70\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1405 - accuracy: 0.9569\n",
            "Epoch 68/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1402 - accuracy: 0.9577\n",
            "Epoch 69/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1395 - accuracy: 0.9580\n",
            "Epoch 70/70\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1391 - accuracy: 0.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a4619af50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F41TsO-in-8m",
        "outputId": "fd0ae5ee-fad3-4887-c893-d53e7ade4f20"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "model_adamax5=keras.Sequential([\n",
        "             keras.layers.Dense(10,input_shape=(784,),activation='sigmoid') , \n",
        "             keras.layers.Dense(100,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  ,\n",
        "             keras.layers.Dense(1000,input_shape=(784,),activation='sigmoid')  \n",
        "                \n",
        "])\n",
        "model_adamax5.compile(\n",
        "    optimizer='Adamax',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "\n",
        ")\n",
        "model_adamax5.fit(x_train_flattened,y_train,epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 1.3466 - accuracy: 0.5406\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6170 - accuracy: 0.8179\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4982 - accuracy: 0.8604\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4368 - accuracy: 0.8776\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3954 - accuracy: 0.8872\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3611 - accuracy: 0.8945\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3366 - accuracy: 0.9017\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3153 - accuracy: 0.9078\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2975 - accuracy: 0.9127\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2842 - accuracy: 0.9161\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2724 - accuracy: 0.9190\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2630 - accuracy: 0.9218\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2546 - accuracy: 0.9247\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2477 - accuracy: 0.9267\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2409 - accuracy: 0.9280\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2355 - accuracy: 0.9305\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2293 - accuracy: 0.9312\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2245 - accuracy: 0.9326\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.2200 - accuracy: 0.9337\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2166 - accuracy: 0.9352\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2116 - accuracy: 0.9364\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2076 - accuracy: 0.9378\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2044 - accuracy: 0.9390\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2009 - accuracy: 0.9401\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1977 - accuracy: 0.9413\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1946 - accuracy: 0.9413\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1919 - accuracy: 0.9427\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1890 - accuracy: 0.9431\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1870 - accuracy: 0.9437\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1839 - accuracy: 0.9449\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1814 - accuracy: 0.9457\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1789 - accuracy: 0.9464\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1771 - accuracy: 0.9467\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1747 - accuracy: 0.9473\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1731 - accuracy: 0.9482\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1709 - accuracy: 0.9485\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1685 - accuracy: 0.9492\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1669 - accuracy: 0.9497\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1659 - accuracy: 0.9499\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1644 - accuracy: 0.9498\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1620 - accuracy: 0.9512\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1610 - accuracy: 0.9509\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1596 - accuracy: 0.9512\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1579 - accuracy: 0.9528\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1571 - accuracy: 0.9518\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1554 - accuracy: 0.9528\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1537 - accuracy: 0.9537\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1529 - accuracy: 0.9535\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1520 - accuracy: 0.9536\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1511 - accuracy: 0.9543\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1496 - accuracy: 0.9547\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1486 - accuracy: 0.9545\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1478 - accuracy: 0.9551\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1463 - accuracy: 0.9553\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1458 - accuracy: 0.9557\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1451 - accuracy: 0.9553\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1436 - accuracy: 0.9561\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1423 - accuracy: 0.9571\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1423 - accuracy: 0.9571\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1415 - accuracy: 0.9572\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1405 - accuracy: 0.9578\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1397 - accuracy: 0.9577\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1390 - accuracy: 0.9580\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1386 - accuracy: 0.9581\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1377 - accuracy: 0.9579\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1364 - accuracy: 0.9584\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1357 - accuracy: 0.9589\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1356 - accuracy: 0.9588\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1345 - accuracy: 0.9595\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1343 - accuracy: 0.9591\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1333 - accuracy: 0.9593\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1326 - accuracy: 0.9600\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1322 - accuracy: 0.9600\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1308 - accuracy: 0.9604\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1306 - accuracy: 0.9605\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1297 - accuracy: 0.9606\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1294 - accuracy: 0.9604\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1290 - accuracy: 0.9607\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1280 - accuracy: 0.9612\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1274 - accuracy: 0.9612\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1274 - accuracy: 0.9618\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1262 - accuracy: 0.9619\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1263 - accuracy: 0.9613\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1253 - accuracy: 0.9612\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1248 - accuracy: 0.9622\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1247 - accuracy: 0.9622\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1242 - accuracy: 0.9619\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1233 - accuracy: 0.9626\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1230 - accuracy: 0.9627\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1225 - accuracy: 0.9629\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1222 - accuracy: 0.9633\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1213 - accuracy: 0.9634\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1208 - accuracy: 0.9633\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1202 - accuracy: 0.9633\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1200 - accuracy: 0.9631\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1196 - accuracy: 0.9639\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1192 - accuracy: 0.9636\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1184 - accuracy: 0.9634\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1182 - accuracy: 0.9643\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1179 - accuracy: 0.9644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a460b7250>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmdsd9kvoCsZ",
        "outputId": "dff84975-9879-4645-9755-020833ead4e4"
      },
      "source": [
        "y_pred_adamax1=model_adamax1.predict(x_test_flattened)\n",
        "y_pred_adamaxf1=[np.argmax(i) for i in y_pred_adamax1]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adamax_acc1=accuracy_score(y_pred_adamaxf1,y_test)\n",
        "print(adamax_acc1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvzYSt1DoUG8",
        "outputId": "84deb90f-a4a4-40d7-90c5-533b214afd56"
      },
      "source": [
        "y_pred_adamax2=model_adamax2.predict(x_test_flattened)\n",
        "y_pred_adamaxf2=[np.argmax(i) for i in y_pred_adamax2]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adamax_acc2=accuracy_score(y_pred_adamaxf2,y_test)\n",
        "print(adamax_acc2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FkfOYgrodQ-",
        "outputId": "56097a03-f6ef-47e5-b7c1-3a93c0068601"
      },
      "source": [
        "y_pred_adamax3=model_adamax3.predict(x_test_flattened)\n",
        "y_pred_adamaxf3=[np.argmax(i) for i in y_pred_adamax3]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adamax_acc3=accuracy_score(y_pred_adamaxf3,y_test)\n",
        "print(adamax_acc3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw4XgrUhorlv",
        "outputId": "d9e9df76-0590-46a9-f7cb-7abaa2acb15d"
      },
      "source": [
        "y_pred_adamax4=model_adamax4.predict(x_test_flattened)\n",
        "y_pred_adamaxf4=[np.argmax(i) for i in y_pred_adamax4]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adamax_acc4=accuracy_score(y_pred_adamaxf4,y_test)\n",
        "print(adamax_acc4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbEXjnllov28",
        "outputId": "af77e7a4-4566-4ac4-c6d5-d7ddc3fe371a"
      },
      "source": [
        "y_pred_adamax5=model_adamax5.predict(x_test_flattened)\n",
        "y_pred_adamaxf5=[np.argmax(i) for i in y_pred_adamax5]\n",
        "from keras import metrics \n",
        "from sklearn.metrics import *\n",
        "adamax_acc5=accuracy_score(y_pred_adamaxf5,y_test)\n",
        "print(adamax_acc5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFFab3Txo1R4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}