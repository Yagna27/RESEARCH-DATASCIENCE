{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/Test Data.csv\n/kaggle/input/dataset/Training Data.csv\n/kaggle/input/dataset/Sample Prediction Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data=pd.read_csv(\"../input/dataset/Training Data.csv\")\ntest_data=pd.read_csv(\"../input/dataset/Test Data.csv\")","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data.shape","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(252000, 13)"},"metadata":{}}]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Id   income  age  experience  married house_ownership car_ownership  \\\n0   1  1303835   23           3   single          rented            no   \n1   2  7574516   40          10   single          rented            no   \n2   3  3991815   66           4  married          rented            no   \n3   4  6256451   41           2   single          rented           yes   \n4   5  5768871   47          11   single          rented            no   \n\n            profession                 city           state  \\\n0  Mechanical_engineer                 Rewa  Madhya_Pradesh   \n1   Software_Developer             Parbhani     Maharashtra   \n2     Technical_writer            Alappuzha          Kerala   \n3   Software_Developer          Bhubaneswar          Odisha   \n4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu   \n\n   current_job_years  current_house_years  risk_flag  \n0                  3                   13          0  \n1                  9                   13          0  \n2                  4                   10          0  \n3                  2                   12          1  \n4                  3                   14          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>income</th>\n      <th>age</th>\n      <th>experience</th>\n      <th>married</th>\n      <th>house_ownership</th>\n      <th>car_ownership</th>\n      <th>profession</th>\n      <th>city</th>\n      <th>state</th>\n      <th>current_job_years</th>\n      <th>current_house_years</th>\n      <th>risk_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303835</td>\n      <td>23</td>\n      <td>3</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Mechanical_engineer</td>\n      <td>Rewa</td>\n      <td>Madhya_Pradesh</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Software_Developer</td>\n      <td>Parbhani</td>\n      <td>Maharashtra</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>married</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Technical_writer</td>\n      <td>Alappuzha</td>\n      <td>Kerala</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>yes</td>\n      <td>Software_Developer</td>\n      <td>Bhubaneswar</td>\n      <td>Odisha</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>single</td>\n      <td>rented</td>\n      <td>no</td>\n      <td>Civil_servant</td>\n      <td>Tiruchirappalli[10]</td>\n      <td>Tamil_Nadu</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data[\"profession\"]=pd.factorize(train_data.profession)[0]\ntrain_data[\"city\"]=pd.factorize(train_data.city)[0]\ntrain_data[\"state\"]=pd.factorize(train_data.state)[0]\ntrain_data[\"married\"]=pd.factorize(train_data.married)[0]\ntrain_data[\"house_ownership\"]=pd.factorize(train_data.house_ownership)[0]\ntrain_data[\"car_ownership\"]=pd.factorize(train_data.car_ownership)[0]","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Id   income  age  experience  married  house_ownership  car_ownership  \\\n0   1  1303835   23           3        0                0              0   \n1   2  7574516   40          10        0                0              0   \n2   3  3991815   66           4        1                0              0   \n3   4  6256451   41           2        0                0              1   \n4   5  5768871   47          11        0                0              0   \n\n   profession  city  state  current_job_years  current_house_years  risk_flag  \n0           0     0      0                  3                   13          0  \n1           1     1      1                  9                   13          0  \n2           2     2      2                  4                   10          0  \n3           1     3      3                  2                   12          1  \n4           3     4      4                  3                   14          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>income</th>\n      <th>age</th>\n      <th>experience</th>\n      <th>married</th>\n      <th>house_ownership</th>\n      <th>car_ownership</th>\n      <th>profession</th>\n      <th>city</th>\n      <th>state</th>\n      <th>current_job_years</th>\n      <th>current_house_years</th>\n      <th>risk_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1303835</td>\n      <td>23</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>7574516</td>\n      <td>40</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3991815</td>\n      <td>66</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6256451</td>\n      <td>41</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5768871</td>\n      <td>47</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y_labels=train_data[\"risk_flag\"]\nx_features=train_data.drop([\"risk_flag\"],axis=1)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def model_fit(x,y):\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n    model = LogisticRegression().fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(accuracy_score(y_test, y_pred))\n    \n    ","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_fit(x_features,y_labels)","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0.8759325396825397\n","output_type":"stream"}]},{"cell_type":"code","source":"#random sampling\ndata1=train_data[train_data.risk_flag==0]\ndata2=train_data[train_data.risk_flag==1]\ndata3=data1.sample(n=40000)\nrandom_train_data=data3.append(data2)\nrandom_train_data.shape","metadata":{"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(70996, 13)"},"metadata":{}}]},{"cell_type":"code","source":"random_y_labels=random_train_data[\"risk_flag\"]\nrandom_x_features=random_train_data.drop([\"risk_flag\"],axis=1)","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_fit(random_x_features,random_y_labels)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"0.5654225352112676\n","output_type":"stream"}]},{"cell_type":"code","source":"#stratify sampling\ndef stratify_model_fit(x,y):\n    X_train, X_test, y_train, y_test = train_test_split(x, y,stratify=y, test_size=0.2, random_state=42)\n    model = LogisticRegression().fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"stratify_model_fit(x_features,y_labels)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"0.8770039682539682\n","output_type":"stream"}]},{"cell_type":"code","source":"stratify_model_fit(random_x_features,random_y_labels)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"0.5633802816901409\n","output_type":"stream"}]},{"cell_type":"code","source":"#reserviour sampling \nimport random\ndef generator(max):\n    number = 1\n    while number < max:\n        number += 1\n        yield number\n# Create as stream generator\nstream = generator(10000)\n# Doing Reservoir Sampling from the stream\nk=5\nreservoir = []\nfor i, element in enumerate(stream):\n    if i+1<= k:\n        reservoir.append(element)\n    else:\n        probability = k/(i+1)\n        if random.random() < probability:\n            # Select item in stream and remove one of the k items already selected\n             reservoir[random.choice(range(0,k))] = element\nprint(reservoir)","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[7325, 5195, 3822, 8966, 9802]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom imblearn.over_sampling import *","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import TomekLinks\n\ntl = TomekLinks(return_indices=True, ratio='majority')\nX_tl, y_tl, id_tl = tl.fit_sample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-ba227dfb6142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTomekLinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTomekLinks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'majority'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_tl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m             )\n\u001b[1;32m    593\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'return_indices'"],"ename":"TypeError","evalue":"__init__() got an unexpected keyword argument 'return_indices'","output_type":"error"}]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(ratio='minority')\nX_sm, y_sm = smote.fit_sample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-72eb3a6b39d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minority'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m             )\n\u001b[1;32m    593\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ratio'"],"ename":"TypeError","evalue":"__init__() got an unexpected keyword argument 'ratio'","output_type":"error"}]},{"cell_type":"markdown","source":"Variations of Oversampling techniques:\nRandomOverSampler,\nSMOTE,\nBorderLineSMOTE,\nKMeansSMOTE,\nSVMSMOTE,\nADASYN,\nSMOTENC,\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"sm = RandomOverSampler(random_state=42)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0.5096491029614715\n","output_type":"stream"}]},{"cell_type":"code","source":"sm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0.5114703287255944\n","output_type":"stream"}]},{"cell_type":"code","source":"sm = BorderlineSMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"0.512522341123504\n","output_type":"stream"}]},{"cell_type":"code","source":"sm = KMeansSMOTE(random_state=42, cluster_balance_threshold=0.1)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"0.6524439215863715\n","output_type":"stream"}]},{"cell_type":"code","source":"sm = SVMSMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm = ADASYN(random_state=42)\nX_res, y_res = sm.fit_resample(x_features,y_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fit(X_res, y_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}